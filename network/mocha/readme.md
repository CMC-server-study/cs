## OSI 7계층

OSI(Open Systems Interconnection) 모델은 통신 시스템의 설계와 문제 해결을 위한 개념적 모델입니다. 이 모델은 통신 시스템을 7개의 계층으로 나누어 각 계층별로 역할과 기능을 정의하고 있습니다.

1. 물리 계층 (Physical Layer)
    - 전기적, 물리적인 특성을 이용하여 데이터를 전송함
    - 데이터의 비트 단위 전송과 물리적인 매체의 전송 방법을 정의함
2. 데이터 링크 계층 (Data Link Layer)
    - 물리적인 매체를 통해 연결된 두 장치 간의 데이터 전송을 관리함
    - 데이터를 프레임 단위로 나누어 송수신하고, 오류 검출 및 수정을 수행함
3. 네트워크 계층 (Network Layer)
    - 여러 개의 노드들을 거칠 때마다 경로를 찾아주는 역할을 함
    - 데이터의 경로 설정과 전송 방법을 정의함
4. 전송 계층 (Transport Layer)
    - 데이터의 신뢰성 있는 전송을 보장함
    - 오류 검출 및 재전송, 흐름 제어와 혼잡 제어를 수행함
5. 세션 계층 (Session Layer)
    - 양 끝단의 응용 프로세스가 통신을 관리하기 위한 방법을 제공함
    - 데이터 전송을 위한 세션 연결 설정 및 유지, 종료 등의 기능을 수행함
6. 표현 계층 (Presentation Layer)
    - 데이터의 형식을 정의하고, 데이터를 인코딩 및 디코딩함
    - 데이터의 형식 변환, 암호화, 복호화 등의 기능을 수행함
7. 응용 계층 (Application Layer)
    - 최종 사용자가 사용하는 서비스를 제공함
    - HTTP, FTP, SMTP 등과 같은 프로토콜이 이 계층에서 동작함

각 계층은 서로 독립적이고 상호 작용한다. 하위 계층은 상위 계층에 대한 서비스를 제공하고, 상위 계층은 하위 계층에서 제공된 서비스를 이용하여 자신의 서비스를 제공한다. 이러한 계층 구조는 시스템의 모듈화, 개방성, 유지보수성 등을 향상시키는 장점이 있다.

<br>

## TCP / IP

TCP와 IP는 인터넷 프로토콜 스택의 핵심 프로토콜로서, 데이터의 전송을 담당한다.


### TCP
TCP는 데이터의 신뢰성 있는 전송을 보장해준다.
이를 위해 전송 중 발생할 수 있는 오류나 손실을 검사하고 복구하는 기능을 가지고 있다.
TCP는 SYN, ACK, Window Size 등의 정보를 추가하여 데이터 전송의 안정성을 보장한다.


### IP
IP는 인터넷상에서 데이터를 전송하기 위해 사용되는 프로토콜이다.
패킷을 전송할때 패킷에 출발지 IP 주소와 도착지 IP 주소를 IP헤더에 추가해서 전송한다.
이를 사용해서 데이터를 라우팅 하고 목적지에 도달할 수 있도록해준다.
TCP와는 다르게 자체적으로 오류 검사가 복구 기능을 가지고 있지 않다.

### TCP, IP의 역할

두 프로토콜은 서로 보완적인 역할을 수행하며, TCP/IP라는 프로토콜 스택으로 함께 사용된다.

**TCP의 역할**
- **데이터의 신뢰성**을 보장

**IP의 역할**
- 데이터의 경로 설정과 전송을 담당

<br>

## TCP / UDP


|.| TCP       | 	UDP     |
|---|-----------|----------|
|연결 방식| 	연결형 서비스  |	비연결형 서비스|
|패킷 교환| 	가상 회선 방식 |	데이터그램 방식|
|전송 순서 보장| 	보장함      |	보장하지 않음|
|신뢰성| 	높음       |	낮음|
|전송 속도	| 느림        | 	빠름       |

- TCP는 패킷 손실과 오류 감지,복구 등의 기능이 포함되어 있다. 따라서 신뢰성 있는 데이터 전송이 필요한 금융권 서비스에 TCP가 적합하다.
- UDP는 오류 감지나 손실 감지 메커니즘은 없지만, 핸드쉐이크 과정을 제외했기에 전송 속도가 매우 빠르다. 일정량의 손실을 허용하는 비디오 스트리밍 서비스 등에 적합하다.

<br>

## TCP의 3 way handshake와 4 way handshake

TCP의 연결 지향적 특징으로 인해 연결 생성과 연결 종료 시에 매번 핸드쉐이킹 과정을 거친다.

### 3-way handshaking

3-way handshaking은 연결을 생성할때 필요한 과정이다.

<img width="400" alt="3-way handshaking" src="https://user-images.githubusercontent.com/82302520/226425174-6868cb71-ff95-43fa-82fe-6b9db920c32c.png">

1. 요청자가 SYN_SENT 단계에서 랜덤으로 생성한 SYN를 보낸다
2. 수신자는 SYN_RECV 단계에서 요청자의 SYN에 1을 더한 ACK와 랜덤한 SYN를 보낸다
3. 요청자는 ESTABLISHED 단계에서 수신자의 SYN에 1을 더한 ACK를 보낸다
4. 연결 생성 완료

### 4-way handshaking

4-way handshaking은 연결을 종료할때 필요한 과정이다. 연결을 종료하는 핸드쉐이킹이 따로 필요한 이유는 강제로 연결을 종료할 시,
연결이 끊겼다는걸 **상대방이 인지하지 못하고**, 미처 **전송이 완료되지 못한 데이터가 있을 수도 있기 때문이다**.

<img width="400" alt="4-way-handshaking" src="https://user-images.githubusercontent.com/82302520/226425218-21cba66a-0e28-47f5-be22-743245fd0646.png">


1. 요청자가 FIN_WAIT_1 단계에서 FIN과 ACK를 같이 보낸다.
2. 수신자는 CLOSE_WAIT 단계에서 요청자에게 ACK를 보내고 남은 데이터를 보내기 시작한다.
3. 요청자는 수신자의 ACK를 받은 후, 수신자의 데이터 전송이 끝날때까지 대기 한다.
4. 수신자는 데이터 전송이 끝날 경우 LAST_ACK 단계로 진입해서 요청자에게 FIN을 보낸다. 이후 요청자의 ACK이 올때까지 대기
5. 요청자는 FIN을 받고 TIME_WAIT 단계로 진입 후, 수신자에게 ACK 보낸다.
6. 연결 종료

> 4-way handshake에서는 수신측의 남은 데이터를 모두 전송할 수 있도록 half-open 기법이 사용된다는게 중요함. 요청자는 이때 수신 스트림만 열고 수신자의 남은 데이터 처리해준다.

<br>

## TCP의 흐름제어, 혼잡제어

### TCP의 흐름 제어

TCP 연결에서 보통 수신측의 처리 속도보다 송신측의 송신 속도가 더 빠르면 문제가 생긴다. 수신측이 처리하는 동안 요청은 수신측의 수신 버퍼에 쌓이게 되고 버퍼가 꽉차면 마지막에 들어오려는 데이터는 폐기처분 된다.

따라서 송신측은 수신측의 데이터 처리 속도가 얼마인지 미리 파악하고 그에 맞는 양의 데이터를 전송해야 한다. 수신측은 자신이 처리할 수 있는 양을 의미하는 윈도우 크기를 응답 헤더에 담아서 송신측에 전달한다.

### Sliding Window

오늘날의 TCP는 보통 슬라이딩 윈도우 방식을 사용해서 흐름 제어를 구현한다. 송신측은 매번 데이터 전송이 가능한지 체크할 필요 없이, 수신측의 윈도우 사이즈를 알고 있다면 매번 송신 버퍼에서 윈도우 크기 만큼 데이터를 전송하면 된다.

송신측의 윈도우 크기는 3-way handshake 과정에서 결정된다.

송신측은 처음 SYN를 보내고 수신측으로부터 SYN+ACK를 받기까지의 시간을 측정하고 (RTT), 이를 통해서 네트워크 상황 유추한다. 윈도우 크기는 차후 네트워크 상황에 따라 유동적으로 변경된다.

윈도우 크기만큼 전송 후, 수신측으로부터 남은 버퍼공간을 기반으로한 윈도우 사이즈 정보를 받으면 그만큼 window를 밀어서 데이터를 전송시킨다.

> 송신측의 윈도우 사이즈가 결정된 뒤, 수신 측은 매번 얼마의 데이터를 보내면 되는지 알려준다. 그러면 초기 윈도우 사이즈 내에서 계속 윈도우를 넘겨가며 버퍼 내의 데이터를 보낸다. 만약 전송 가능 데이터가 계속 많아지면 네트워크 상황이 좋은 것이므로 윈도우 크기 슬슬 키우면 된다.

### 오류 제어

TCP는 기본적으로 ARQ 기반 오류 제어 사용한다. 보통 이 재전송 과정을 줄이기 위한 방법들을 추가로 사용한다.

수신측이 NACK을 보내는 방법과 ACK의 도착 유무로 판단하는 방법이 있다. 보통은 ACK을 사용한다.

오류가 날 수 있는 3가지 상황
- 송신측이 보낸 데이터가 중간에 유실되어 수신측이 ACK을 안보내는 경우
- 수신측이 ACK을 보냈지만 ACK이 중간에 유실되는 경우
- 송신측이 중복된 ACK를 받는 경우

### 오류 제어 방법 2가지

**Go Back N**

데이터를 연속적으로 보내다가 어느 데이터부터 오류가 발생했는지 검사하는 방법

1. 연속된 데이터를 보낸다.
2. 다 성공적으로 도착했으면 ACK 보냄
3. 만약 중간에 하나라도 유실됐으면 수신측은 그 유실된 데이터 이후의 데이터를 모두 다 버리고 송신측에 어디부터 유실됐는지 알려줌
4. 송신측은 그 유실된 데이터부터의 데이터를 다시 보냄

**Selective Repeat**

Go Back N과 반대로 유실된 데이터만 다시 보내는 방식이다. 선택적으로 재전송 할 수 있기에 효율적이라는 장점이 있지만, 새 데이터를 보내면 별도의 재정렬 과정을 거쳐야 한다는 단점이 있다.

> 재전송이 이득인 상황에서는 Go Back N을 재정렬이 유리한 상황에서는 Selective Repeat을 사용하면 된다.

### 혼잡 제어

네트워크 환경에서 통신 오류가 발생할 경우 기본적인 복구 방식은 재시도이다. 하지만 혼잡상황에서 재시도가 많아지면 혼잡도를 더욱 증가시킬 수 있다. 따라서 혼잡상황에서 송신측은 데이터의 전송량을 유동적으로 조절할 수 있어야 한다.

송신 측은 자신의 최종 윈도우 크기를 정할 때 수신 측이 보내준 윈도우 크기인 수신자 윈도우(RWND), 그리고 자신이 네트워크의 상황을 고려해서 정한 윈도우 크기인 혼잡 윈도우(CWND) 중에서 더 작은 값을 사용한다.

### 혼잡 윈도우 크기 초기화하기

- MSS : 한 세그먼트에 최대로 보낼 수 있는 데이터의 양을 나타내는 값
- MTU(Maximum Transmission Unit) : 한번 통신 때 보낼 수 있는 최대 단위

MSS = MTU - (IP헤더길이 + IP옵션길이) - (TCP헤더길이 + TCP옵션길이)

- TCP 환경에서 기본적인 MTU 크기 : 1500 bytes
- MSS = 1500 - 40 = 1460 Bytes
- 초기 혼잡 위도우 크기 == 1MSS


### 가장 기본적인 혼잡 제어 방법
- AIMD
- Slow Start

**AIMD (Additive Increase / Multicative Decrease)**

네트워크가 문제가 없을때는 혼잡 윈도우의 크기를 1씩 증가시킨다. 하지만 중간에 데이터가 유실되거나 응답이 오지 않는 등의 혼잡 상태 감지되면 혼잡 윈도우 크기를 반으로 줄인다.

> 이 방식은 네트워크에 늦게 참여하는 노드에게 유리

- 이미 대역폭을 많이 사용하고 있는 노드는 혼잡 제어를 통해 윈도우 크기를 반으로 줄일 확률이 높음
- 새로 들어온 노드는 남은 대역폭을 사용해서 본인은 혼잡 윈도우 크기 줄일 수 있다.

AIMD의 문제점 : 현대의 네트워크는 대역폭이 넉넉하다. 하지만 이 방식은 윈도우 크기를 너무 작게 키우기 때문에 네트워크의 대역폭을 제대로 사용하지 못한다.

**Slow Start**

네트워크 대역폭을 제대로 활용하지 못하는 AIMD 방식을 대신해서 윈도우 크기 증가 시 지수적으로 증가시키는 Slow Start 방식이 있다.

- 네트워크 여유로울 시 : 지수적으로 윈도우 크기를 증가
- 혼잡 감지 시 : 윈도우 크기를 1로 줄여버린다

최근의 TCP 에서 사용하는 Tahoe나 Reno가 AIMD와 Slow Start를 적절히 섞어서 사용한다.


### 혼잡 제어 정책 종류

**Tahoe**

<img width="400" alt="스크린샷 2023-02-23 오후 10 49 31" src="https://user-images.githubusercontent.com/82302520/226426571-e6f83cb1-a2d3-462f-ab5e-af8f8252e4b3.png">

- 3 ACK Duplicated나 Timeout 발생하면 1로 줄여버린다.
- 혼잡 상황에서의 문제가 발생했을때의 혼잡 윈도우 크기의 반을 딱 ssthreshold로 다시 잡는다

단점 : 초반 slow start 구간에 키우는데 너무 오래 걸림, 윈도우 크기 1부터 다시 키워야함

**RENO**

<img width="400" alt="스크린샷 2023-02-23 오후 10 49 40" src="https://user-images.githubusercontent.com/82302520/226426601-e503de0b-adb5-42f7-8072-551dbd890787.png">

- 3 ACK Duplicated는 AIMD로 줄이고 ssthreshold도 거기에 맞게 줄인다.
- Timeout은 1로 줄이되 ssthreshold를 반으로 줄이지 않는다.

<br>

## 데이터 캡슐화

데이터를 상위나 하위 계층으로 보내는 과정에서 헤더 정보를 덧붙이는 과정을 캡슐화라고 한다. 데이터 송신측에서 데이터를 캡슐화해서 보내면 수신측에서는 다시 역캡슐화 해서 원하는 데이터를 얻는다.

**헤더**
- 캡슐화, 역캡슐화 시에 덧붙이는 출발지 정보, 목적지 정보 또는 오류 체크 등에 필요한 정보
### PDU (Protocol Data Unit)

네트워크에서는 계층마다 데이터 단위를 부르는 이름이 다르다.
- 응용 계층의 데이터 형식 : 메세지
- TCP 헤더가 붙은 데이터 형식 : 세그먼트
- IP 헤더가 붙은 데이터 형식 : 패킷
- 이더넷 헤더와 트레일러가 붙은 데이터 형식 : 프레임

### MTU vs MSS

MTU (Maximum Transmission Unit)
- 한번의 통신으로 보낼 수 있는 데이터의 최대 크기이다. 보통 1500 bytes를 사용한다.

MSS (Maximum Segment Size)
- 한번의 통신으로 보낼 수 있는 순수한 데이터의 크기이다.
- MTU - IP 헤더 (20 bytes) - TCP 헤더 (20 bytes) = 1460 bytes

<br>

## HTTP1 vs HTTP1.1 vs HTTP2 vs HTTP3

### HTTP1
- 커넥션 하나 당 하나의 요청만 보낼 수 있었다
- 매번 요청 하나 보낼때마다 재연결을 위한 핸드셰이크 과정을 거쳐야 했기에 비효율적이었다

### HTTP1.1

- Keep-Alive header를 통해 기존 연결과의 handshake 생략 가능하다, 즉 커넥션을 재사용 가능하다
- 하나의 커넥션에서 여러 요청을 보내는 것이 가능하다
- 하나의 커넥션을 통해 여러 데이터가 동기적인 순서를 가지고 들어온다. 만약 하나가 지연되면 뒤의 요청에 대한 응답도 모두 지연된다. 이를 HOL Blocking이라고 한다.
### HTTP2

- HTTP/2는 하나의 TCP 연결을 통해 여러 데이터 요청을 병렬로 전송할 수 있다. (Multiplexing을 통한 HOL 블로킹 문제 해결)
- HTTP/2는 중복 헤더 프레임을 압축해서 전송한다. 클라이언트와 서버에서 모두 이전 요청에 사용된 헤더 목록을 유지관리함. 모바일과 같이 업로드 대역폭이 상대적으로 작은 경우에는 이런 HTTP 헤더 압축 방법이 특히 유용하다.

### HTTP3 

- UDP 기반의 프로토콜을 사용한다. UDP는 기존의 TCP에서 많은 시간을 잡아먹었던 handshaking 과정이 없기에 낮은 레이턴시를 가진다.
- HTTP3는 Connection Id를 사용해서 클라이언트와 커넥션을 맺는다. IP 기반으로 연결을 맺을 경우, 자주 네트워크가 변경되는 모바일 환경에서는 커넥션이 끊길
확률이 높다. 이는 3-way handshake가 발생할 가능성이 높아진다는 말이고 레이턴시의 증가로 이어진다. HTTP3의 경우 IP와 무관한 랜덤한 값인 Connection Id를 사용하기 때문에 네트워크 변경에 영향을 받지 않고 클라이언트와 연결을 유지할 수 있다.

<br>

## HTTP의 GET과 POST

| 제목 셀1      | GET    | POST        |
|------------|--------|-------------|
| 캐시         | O      | X           |
| 북마크 추가     | O      | X           |
| 데이터 길이 제한  | O      | X           |
| HTTP 응답 코드 | 200 OK | 201 Created |
| 사용 용도      | 리소스 요청 | 리소스 생성      |
| 리소스 전달 방식  | 쿼리 스트링 | HTTP BODY   |
| 멱등성        | O | X   |

<br>

## HTTP 요청 응답 헤더

### HTTP 응답 헤더 주요 항목

**HTTP 버전, 응답 코드**

- HTTP 버전 정보- HTTP 프로토콜에 정의된 응답코드 ex) HTTP/1.1 200 OK

**Server**

- 웹 서버의 정보를 명시 ex) Server : Apache/2.2.24

**Location**

- 응답코드 301, 302 리다이렉션 상태에서 위치 정보를 지정

**Set-Cookie**

- 클라이언트에 저장할 쿠키 정보를 지정

    - Expires : 만료일
    - Secure : HTTPS에서만 사용
    - HttpOnly : 스크립트에서 접근 불가
    - Domain : 같은 도메인에서만 사용

**Expires**

- 해당 리소스의 유효 일시를 지정

**Allow**

- 응답 코드 405 (Method Not Allowed) 상태에서 서버가 제공할 수 있는 HTTP 메서드를 지정

<br>

## HTTP와 HTTPS 동작 과정

SSL 계층은 인터넷에서 데이터를 안전하게 전송하기 위한 프로토콜이다. SSL은 TCP/IP 스택 위에 구현되며 전송 계층과 응용 계층 사이에 위치한다.

SSL은 데이터의 안전성을 보장하기 위해 데이터를 암호화 하고, 인증 및 기밀성의 기능을 제공한다. SSL 사용하면 통신 중에 제 3자가 데이터를 가로채도 데이터가 암호화 되어있기에 인식할 수 없다. 즉, 데이터의 안전성이 보장된다.

### SSL 통신 절차

SSL 계층은 SSL 핸드셰이크 프로토콜과 SSL 레코드 프로토콜로 구성된다.

- SSL 핸드셰이크 프로토콜 : 클라이언트와 서버 간의 SSL 연결을 설정하는 역할이다. 암호화 방식 및 인증서 정보를 교환한다.
- SSL 레코드 프로토콜 : 클라이언트와 서버 간에 실제 데이터를 전송하는 과정이다.

> SSL은 더 나은 기밀성을 제공하는 TLS로 대체되었지만, 아직 예전 웹사이트들은 SSL을 사용하기도 한다.

### SSL 인증 과정

1. 서버는 자신의 정보와 공개키를 CA로 전달한다.
2. CA는 자신의 개인키로 SSL 인증서를 암호화 후 서버에 발급해준다.
3. 서버는 암호화된 SSL 인증서를 웹 브라우저로 보낸다.
4. 웹브라우저는 CA의 개인키로 암호화된 SSL 인증서를 CA의 공개키로 복호화한다.
5. 웹브라우저는 서버의 공개키를 얻어낸다.
6. 웹브라우저는 데이터 암호화에 사용할 비밀키(대칭키)를 서버의 공개키로 암호화 후 서버로 보낸다.
7. 서버는 자신의 개인키로 복호화 후, 데이터 암호화에 사용할 비밀키(대칭키)를 얻어낸다.

### SSL Handshake

TCP 3-way Handshake 과정이 끝난 후, SSL Handshake 과정이 발생한다.

<img width="400" alt="스크린샷 2023-03-20 오후 7 30 16" src="https://user-images.githubusercontent.com/82302520/226424665-e563dece-d45c-4272-b5cc-7bfbc433aad8.png">


1. ClientHello : 클라이언트 측에서 처리 가능한 암호화 알고리즘을 전달해준다.
2. ServerHello : 서버 측에서 한가지 암호화 알고리즘을 선택한다.
3. Certificate : CA의 개인키로 암호화된 SSL 인증서를 브라우져에게 보낸다.
4. ClientKeyExchange : SSL 인증서를 CA의 공개키로 복호화 하고 서버의 공개키를 얻어냄. 이걸로 비밀키를 암호화 후 서버에게 전송.
5. Finished : 서버는 자신의 공개키로 암호화된 비밀키를 자신의 개인키로 복호화하고, 이제 서버와 클라이언트는 암호화에 사용될 대칭키를 둘 다 가지게 됨.

<br>

## CORS

CORS(Cross-Origin Resource Sharing)란, 웹 브라우저에서 실행되는 JavaScript 코드에서 발생하는 보안 상의 이슈 중 하나다.
보안 상의 이유로, 브라우저는 다른 도메인(출저)에 속한 자원(예: 다른 서버에 있는 이미지, 동영상, 스크립트 파일 등)을 자동으로 요청할 수 없다.
이를 Same-Origin Policy(SOP)라고 한다.

### 같은 출저의 기준

> https://www.naver.com:443/mail 에서 443 포트까지가 같은 출저(도메인)이라고 부른다.

하지만, 웹 애플리케이션을 개발하다 보면, 다른 도메인에 있는 자원을 사용해야 하는 경우가 있다. 이를 위해 SOP에는 CORS라는 예외 조항을 둬서 SOP는 위반했더라도 CORS 지켰다면 다른 도메인에서도 데이터를 요청할 수 있도록 만들었다.

### CORS의 동작 원리

1. 웹브라우저가 서버로 요청할때 클라이언트의 출저를 담은 Origin 필드를 헤더에 포함해서 본 요청 이전에 Option 메서드를 통한 예비 요청을 보낸다.
2. 서버는 허용하고자 하는 출저 목록을 Access-Control-Allow-Origin 필드에 담아서 전송한다.
3. 웹브라우저는 서버에서 보낸 Access-Control-Allow-Origin 필드와 Origin 필드를 비교해서 위반 여부 판별한다.
4. 위반 여부를 기준으로 CORS를 위한 안했다면 본 요청을 보내고, 위반했다면 경고창을 띄운뒤 받아온 데이터는 버린다.

CORS는 다른 도메인 간의 자원 공유를 보다 쉽고 안전하게 할 수 있도록 도와주는 기술이다.
하지만, 이를 잘못 구성하면 보안 상의 문제가 발생할 수 있으므로, 적절한 설정이 필요하다.
즉, 웬만하면 Access-Control-Allow-Origin을 * 로 설정하지 말고 필요한 Origin들만 등록해주자

<br>

## REST와 RESTful

REST(Representational State Transfer)는 웹 상의 자원을 이름(URI)으로 구분하여, 해당 자원의 상태(Representational)를 주고 받는 방식을 말한다. REST는 웹의 기존 동작을 이용하며, HTTP 프로토콜을 따르는 모든 플랫폼에서 사용이 가능하다.

RESTful은 REST를 구현하는 웹 서비스의 아키텍처를 의미한다. RESTful은 다음과 같은 원칙들을 따른다.

1. 자원(URI) - 모든 자원은 고유한 ID인 URI를 가지고 있어야 한다.
2. 행위(HTTP Method) - HTTP 프로토콜을 따르는 GET, POST, PUT, DELETE 등의 메소드를 사용하여 자원에 대한 행위를 표현한다.
3. 표현(Representations) - 서버가 클라이언트에게 보내주는 자원은 JSON, XML 등과 같은 포맷을 사용하여 표현된다.
4. 자기서술적 메시지(Self-descriptive message) - 각 요청은 그 자체로 요청에 필요한 모든 정보를 가지고 있어야 한다. 즉, 요청에 대한 설명이 요청 메시지에 포함되어 있어야 한다.
5. 하이퍼미디어(Hypermedia) - 서버는 클라이언트에게 다음에 취할 수 있는 옵션에 대한 링크를 제공해야 한다. (HETAOS)

RESTful 아키텍처를 따르는 웹 서비스는 간단하고 확장성이 좋으며, 서로 다른 클라이언트 플랫폼에서도 사용이 가능하다.

<br>

## 소켓

소켓은 네트워크 상에서 돌아가는 두 개의 프로그램 간 양방향 통신의 하나의 엔드포인트이다. 소켓은 포트 번호에 바인딩 되어 TCP 레이어에서 네트워크 통신을 진행하는 애플리케이션을 식별할 수 있게 한다. 소켓은 전송 계층과 응용 계층 사이의 인터페이스 즉, 사용자가 커널을 사용할 수 있도록 추상화를 시켜준다.

프로세스는 소켓을 통해서 외부와 통신을 하게 되는데, 소켓은 리눅스에서 파일로 다루어지며 프로세스는 이 소켓을 사용할때 파일디스크립터를 통해 사용한다.

### 소켓의 종류

**1. 스트림 소켓**

- TCP를 사용하는 연결 지향방식의 소켓이다
- 송수신자의 연결을 보장하여 신뢰성 있는 데이터 전송 가능하게 한다
- 데이터의 순서 보장해준다

**2. 데이터그램 소켓**

- UDP를 사용하는 비연결지향형 소켓이다
- 데이터의 순서와 신뢰성을 보장하지 않는다

### 소켓과 웹소켓의 차이점

- 동작 계층 : 소켓은 TCP, UDP가 속한 4계층에 위치하지만, 웹소켓은 HTTP에 기반하므로 7계층에 위치한다.
- 데이터 형식 : TCP에 기반한 소켓 통신은 바이트 스트림을 통한 데이터 전송을 하지만, 웹소켓 통신은 메세지 형식의 데이터를 다룬다.

> 웹소켓은 소켓 통신에 기반하여 웹 어플리케이션에 맞게 발전된 형태의 통신이다

> 블로그들을 보면 소켓 통신은 양방향 통신, 커넥션 유지가 가능하다고 한다. 하지만, 이건 웹 소켓에 해당하는 이야기인데 HTTP 자체가 TCP 기반으로 동작하고 결국 소켓을 사용하게 되는데 HTTP도 그럼 양방향 통신이 되는것 아닌가..? 스터디에서 해결하기

<br>

## HTTP vs Websocket

웹소켓은 ws 프로토콜을 기반으로 클라이언트와 서버 사이에 지속적인 완전 양방향 연결 스트림을 만들어 주는 기술이다.

### 기존 HTTP를 사용한 실시간 통신 구현 방법

**1. Polling**

클라이언트가 주기적으로 서버에게 데이터를 요청하는 방식을 말한다. 데이터 업데이트 주기가 불분명한 경우, 불필요한 요청으로 인한 부하가 커진다.

**2. Long Polling**

클라이언트가 서버와 연결한 후, 서버 단에서 데이터가 업데이트 될때까지 연결을 유지한다. 만약 데이터가 업데이트 되면 클라이언트로 데이터를 전달한 후 연결을 끊고, 즉시 새로운 요청을 클라이언트로 보낸다.

주로 소규모 실시간 통신 서비스에서 사용된다.

**3. Streaming**

클라이언트가 한번 서버에 연결한 뒤에 계속 이벤트가 발생할때마다 데이터를 전송 받는 기법이다. 실시간으로 데이터를 전달할 수 있고, 불필요한 요청이 발생하지 않지만 단방향 통신만 제공한다.

> 실시간, 양방향 연결 서비스를 제공하기 위해 웹소켓 기술이 사용된다.

### 웹소켓의 동작 방식

웹소켓은 완전한 양방향 통신 (Full Duplex)을 제공한다

- Half Duplex : 양방향 통신이지만 한번에 한쪽만 데이터 전송 가능하다. ex 무전기
- Full Duplex : 한번에 양쪽에서 모두 데이터를 전송할 수 있다.

**웹소켓 동작 순서**

1. 기존 HTTP 핸드쉐이킹 과정을 거쳐서 연결을 맺는다
2. 연결이 생성되면 HTTP 프로토콜에서 ws 프로토콜로 변환한다
3. 웹소켓을 위한 소켓 생성 후 전이중 통신 진행한다

**웹소켓 방식의 장점**

- HTTP의 경우 매 요청마다 핸드셰이크 과정을 거쳐야 하지만, 웹소켓은 한번만 핸드셰이크를 하면 되므로 응답 시간이 줄어든다.
- HTTP 요청을 사용함으로 80 포트와 443 포트 사용 가능하고 HTTP 기능 그대로 사용 가능하다.

### 웹 소켓 관련 고민해볼 주제

<details>
<summary>모바일 환경에서의 웹소켓</summary>
<div markdown="1">

모바일 환경은 데스크탑 웹 환경과 다르게 실시간으로 네트워크 연결 상태가 변한다. 사용자의 이동에 따라 다른 와이파이를 쓰기도 하고 LTE로 전환할수도 있다.
이때 네트워크가 변동되면 클라이언트 쪽에서는 연결을 끊어버린다. 하지만 강제 종료 즉, 4-way handshake 과정을 거치지 않았기 때문에 서버측에서는 연결이 종료된걸 알지 못한다.

따라서 서버에서 데이터를 보내더라도 클라이언트는 데이터를 받지 못한다. 특히 서버가 데이터를 전송했다고 판단하는 기준은 송신 버퍼에 데이터를 썼는지 여부임으로, 클라이언트가 데이터를 받지 않더라도 서버는 성공으로 판단할 수 있다. 따라서 서버는 클라이언트와의 웹 소켓 연결을 주기적으로 확인하기 위한 수단이 필요하다.
이때 대표적인 방법이 주기적으로 서버와 클라이언트가 health를 체크하는 **ping-pong** 방식이다.

</div>
</details>

<details>
<summary>실시간 통신에서는 웹소켓만으로 충분한가</summary>
<div markdown="1">


웹소켓이 실시간 양방향 통신의 가장 좋은 방법이지만, 웹소켓 통신에 문제가 생길 수 있다. 이때를 대비에서 HTTP 기반 Polling 방식의 실시간 데이터 처리 방식도 차선책으로 만들어놔야 한다.
</div>
</details>

<br>

## 쿠키와 세션

### 쿠키

쿠키는 서버가 어떤 데이터를 브라우저 측에 저장한 후 다시 그 데이터를 받아오는 기술을 말한다. 서버로부터 쿠키를 응답 받은 브라우저는 해당 쿠키를 클라이언트 컴퓨터의 하드디스크에 저장한다. 쿠키는 유효기간이 정해져 있다면 브라우저가 종료되어도 인증이 유지된다. 클라이언트에 최대 300개까지 쿠키를 저장할 수 있고, 하나의 도메인당 최대 20개의 쿠키를 가질 수 있다. 하나의 쿠키값은 4KB까지 저장된다.

### 쿠키의 사용목적

- 세션 관리(Session Management) : 로그인, 사용자 닉네임, 접속 시간, 장바구니 등의 서버가 알아야할 정보들을 저장한다.
- 개인화(Personalization) : 사용자마다 다르게 그 사람에 적절한 페이지를 보여줌
- 트래킹(Tracking) : 사용자의 행동과 패턴을 분석
 

### 쿠키가 사용되는 예시
- ID 저장, 로그인 상태 유지
- 일주일간 다시 보지 않기.
- 최근 검색한 상품들을 광고에서 추천
- 쇼핑몰 장바구니 기능

### 쿠키의 속성

- Expires : 쿠키의 만료 시간을 지정할 수 있다
- Max-Age : 쿠키의 유효 기간을 지정할 수 있다
- Domain : 브라우저가 쿠키를 전송할 도메인을 지정할 수 있다. 서브 도메인까지 포함
- Path : 쿠키를 돌려보낼 구체적인 경로까지 체크한다. 
- Secure : HTTPS 프로토콜 상에서만 쿠키를 서버로 돌려보낸다.
- HttpOnly : 브라우저에서 자바스크립트를 통해서 쿠키에 접근할 수 있다. 서드파티에서 쿠키에 접근하는 것을 방지

### 쿠키의 단점

쿠키는 여러 보안 이슈들의 원인이 되기도 한다.

- 브라우저 환경에서 쿠키를 쉽게 삭제할 수 있으므로 중요한 데이터는 쿠키에 저장하면 안된다.
- 서버가 가지고 있는 것이 아니라 사용자에게 저장되기 때문에, 임의로 고치거나 지울 수 있고, 가로채기도 쉬워 보안이 취약하다.

### 추가 내용

<details>
<summary>서드 파티 쿠키와 CSRF</summary>
<div markdown="1">

### 서드 파티 쿠키
    
사용자가 접속하고 있는 사이트와 다른 도메인으로 보내지는 쿠키

- www.naver.com이라는 도메인에서 www.daum.net에서 제공하는 img를 호출, 이때 www.daum.net의 쿠키를 가지고 있다면 img 호출 과정에서 쿠키를 보내게 되고, 이를 서드 파티 쿠키라고 한다.

```html
<html>
  <head>
    <title>www.naver.com</title>
    <meta property="og:url" content="https://www.naver.com/" />
  </head>
  <body>
    <img src="https://www.daum.net/image.png" />
  </body>
</html>
```
    
- Referer 헤더와 쿠키에 설정된 도메인이 다른 쿠키라고도 한다. 그렇기 때문에 사용자가 www.naver.com에 걸려있는 www.daum.net 링크를 클릭한 경우에 전송되는 쿠키도 서드 파티 쿠키로 취급된다.

### CSRF

CSRF는 Cross-Site Request Forgery의 약자로 쿠키의 동작 방식을 이용한 공격 방법으로 사용자가 자신의 의지와는 무관하게 공격자가 의도한 행위(수정, 삭제, 등록 등)를 특정 웹사이트에 요청하게 하는 공격을 말한다.
    
**CRRF의 과정**
    
1. 이용자는 웹사이트에 로그인하여 정상적인 쿠키를 발급받는다
2. 공격자는 다음과 같은 링크를 이메일이나 게시판 등의 경로를 통해 이용자에게 전달한다. http://www.geocities.com/attacker. 
3. 공격용 HTML 페이지는 다음과 같은 이미지태그를 가진다. <img src= "https://travel.service.com/travel_update?.src=Korea&.dst=Hell"> 해당 링크는 클릭시 정상적인 경우 출발지와 도착지를 등록하기위한 링크이다. 위의 경우 도착지를 변조하였다.
이용자가 공격용 페이지를 열면, 브라우저는 이미지 파일을 받아오기 위해 공격용 URL을 연다.
이용자의 승인이나 인지 없이 출발지와 도착지가 등록됨으로써 공격이 완료된다. 해당 서비스 페이지는 등록 과정에 대해 단순히 쿠키를 통한 본인확인 밖에 하지 않으므로 공격자가 정상적인 이용자의 수정이 가능하게 된다.
    
    
### Same Site 쿠키
    

    </div>
</details>

### 세션

일정 시간 동안 같은 브라우저로부터 들어오는 요청을 하나의 상태로 보고, 그 상태를 유지시키는 기술. 일정 기간은 웹 브라우저가 종료 되기 전까지를 말한다.

**세션의 동작 순서**

1. 클라이언트가 서버에 접속하면 세션 ID를 발급 받는다.
2. 클라이언트는 세션 ID에 대해 쿠키를 사용해서 브라우저에 가지고 있음
3. 클라이언트는 서버에 요청읇 보낼때 세션 ID를 쿠키에 실어서 같이 보냄
4. 서버는 세션 ID를 전달 받고 세션 저장소에 있는 사용자 정보를 가져옴

### 쿠키와 세션의 차이

- 쿠키는 사용자의 브라우저에 저장이 되고 세션의 서버의 저장소에 저장된다.
- 세션은 브라우저가 종료되면 만료 시간에 상관없이 삭제된다. 반면 쿠키는 만료시간을 정하면 브라우저가 종료되도 사용자 인증 정보가 계속 남아있다.
- 쿠키는 클라이언트가 저장하기 때문에 변질되거나 탈취당할 수 있어서 보안적으로 취약하므로 민감 정보를 저장하면 안된다. 반면 세션은 서버에 사용자 정보가 저장되기 때문에 보안적으로 안전하다.

> 쿠키와 세션은 상반되는 기술이 아니라 서로의 약점을 보완하기 위한 기술로 사용될 수 있다. 예를 들어 탈취당하기 쉽다는 쿠키의 약점을 보완해서 쿠키 내부에 민감 정보 대신 SessionID만 저장해서 전송할 수 있다.

<br>

## DNS

DNS은 인터넷 상에서 도메인 이름을 IP 주소로 변환해주는 시스템이다.

DNS는 계층적 구조로 이루어져 있다. 최상위 계층에서는 .com, .org, .edu, .net 등의 도메인 이름들이 정의되어 있으며, 그 아래 계층에서는 구체적인 도메인 이름들이 정의된다.

DNS는 도메인 이름을 IP 주소로 변환하기 위해 DNS 서버를 사용한다. 일반적으로, 인터넷 서비스 제공자(ISP)는 자신의 DNS 서버를 운영하며, 이 DNS 서버를 통해 사용자가 접속하려는 도메인 이름에 해당하는 IP 주소를 얻어온다. DNS 서버는 요청한 도메인 이름에 대한 IP 주소를 캐싱하여, 동일한 도메인 이름에 대한 다음 요청 시에는 캐시된 IP 주소를 사용하여 빠른 응답을 제공한다.

### DNS 요청 흐름
1. 먼저 PC 내의 DNS 캐시를 뒤진다.
2. PC 내의 hosts 파일을 뒤진다.
3. 공유기가 DNS forwarding 기능을 제공한다면 공유기가 DNS 얻어와준다.
4. 만약 DNS forwarding 기능이 없다면 ISP에서 운영하는 DNS를 뒤져서 원하는 IP를 찾아온다.

> DNS 요청을 매번 실제 DNS 서버가 처리한다면 시간이 많이 걸릴 것이다. 따라서 자주 사용한 주소는 캐시를 통해 빠르게 IP를 얻어올 수 있다.

<br>

## DNS Round Robin

DNS 라운드 로빈(Round Robin)은 DNS(Domain Name System) 서버에서 여러 대의 웹 서버를 등록하고, 요청이 들어올 때마다 순차적으로 웹 서버를 선택하여 요청을 전달하는 방식이다.
이를 통해, 부하 분산(Load Balancing)을 구현할 수 있다.

DNS 라운드 로빈은 다수의 웹 서버를 운영하는 대형 웹 사이트에서, 각각의 웹 서버에 대한 부하를 분산시키기 위해 사용된다. DNS 라운드 로빈 방식에서는, 여러 대의 웹 서버 IP 주소를 DNS 레코드에 등록하고, 클라이언트가 해당 도메인 이름으로 접속을 시도하면 DNS 서버가 등록된 웹 서버 IP 주소 중 하나를 선택하여 응답을 전달한다.

**DNS 라운드 로빈의 장점**
- DNS 라운드 로빈 방식은 구현이 간단하고 비용이 저렴하며, 여러 대의 웹 서버를 사용하는 경우 효과적이다.

**DNS 라운드 로빈의 단점**

- 서버의 수 만큼 공인 IP 주소가 필요하다. -> 로드밸런싱은 공인 IP 하나로 모든 트래픽을 받고 나머지 서버는 사설 IP 사용
- 서버에 장애가 발생해도 감지하지 않고 부하 분산시킨다 -> 로드밸런싱은 주기적으로 서버에 헬스 체크 하지만 DNS 라운드로빈은 체크 안한다.
- DNS 결과를 캐싱하기 때문에 균등한 부하 분산이 어렵다.
- 로드밸런싱 대상인 서버가 모두 동일한 스펙일때 효과가 있다.

### 대안이 될 수 있는 로드밸런싱 알고리즘

- Weighted Round Robin : 웹서버 각각에 가중치를 두고 로드밸런싱을 진행할 수 있다.
- Least Connection : 현재 가장 클라이언트 접속이 적은 서버로 로드밸런싱을 진행한다. 각 서버의 커넥션 수 알아야하므로 라운드 로빈만으로는 구현 불가능


### Route 53을 통한 DNS 로드밸런싱
<img width="400" alt="스크린샷 2023-03-20 오후 8 52 51" src="https://user-images.githubusercontent.com/82302520/226424467-4f2a1e0f-dd5b-460a-b9a2-494bf9b5d34d.png">



기존의 DNS 로드밸런싱은 헬스 체크를 하지 못한다는 단점이 있다. 하지만 AWS의 Route 53은 헬스 체크 기능을 제공한다.

### DNS 로드밸런싱 환경에서의 세션

만약 클라이언트와 특정 서버가 세션을 유지하고 있다면 DNS 로드밸런싱을 통해 다른 IP의 서버에 접속할 경우 세션이 끊어질 수 있다. 따라서 세션 클러스터링 같은 적절한 보완책을 사용해야 한다.

<br>

## Nginx와 Apache 웹 서버 차이

### Apache HTTP Server

Apache Software Foundation에서 만든 웹서버 프로그램이다.

### 주요 특징

**1.스레드/프로세스 기반 구조**

- Apache는 클라이언트 요청당 하나의 스레드가 처리하는 구조이다.
- 사용자가 많아지면 스레드 생성과 컨텍스트 스위칭 비용이 많이 들게 되고 메모리 및 CPU 낭비가 심해진다.
- 결과적으로 현대의 웹 환경에서 C10K 문제를 해결하지 못한다. 

**2.Multi-Process Module**

PreFork 방식

- 요청이 들어오기 전에 미리 일정량의 자식 프로세스를 생성한 후, 요청이 들어올때마다 할당함. 프로세스가 부족하면 새로 생성한다.
- 프로세스는 서로 메모리 영역을 공유하지 않기 때문에 안정적인 운영이 가능하지만 메모리 소모가 크다.
- 하나의 자식 프로세스가 하나의 쓰레드를 가지고 최대 1024개의 자식 프로세스 가질 수 있다. 
- Apache에서 기본값으로 사용하는 방식이다.

Worker 방식

- 요청이 들어올때마다 쓰레드를 생성해서 처리하는 구조이다.
- 하나의 프로세스는 최대 64개의 쓰레드를 생성 후 사용할 수 있다.
- Mutli CPU 시스템에서 성능이 좋다.
- 쓰레드 간 메모리 공유를 할 수 있으므로 메모리 사용이 효율적이다.

### 단점
- 많은 Connection이 들어오면 컨텍스트 스위칭 과정이 늘어나기 때문에 CPU 부하가 증가한다.
- 들어오는 커넥션 만큼 프로세스를 생성해야 하기 때문에 메모리 부족 현상이 발생 가능하다.
- Apache 서버의 메인 프로세스가 블로킹 되면 다음 요청을 처리하지 못하고 무한 대기 상태에 빠지게 된다.

> 결론적으로 하나의 프로세스/쓰레드가 하나의 커넥션만 처리하기 때문에 C10K를 해결하지 못한다. Nginx는 이를 해결하기 위해 등장했다.

### Nginx

Nginx는 C10K 문제를 해결하기 위해 만들어진 이벤트 기반의 웹 서버 소프트웨어이다.

### Nginx 특징

**이벤트 기반 처리 구조**

- Nginx는 워커 프로세스의 생명주기를 관리하는 마스터 프로세스와 실제 커넥션을 처리하는 워커 프로세스로 구성되어있다.
- 워커 프로세스가 생성될때 지정된 listen 소켓을 배정 받는다. 소켓에 요청이 들어오면 커넥션을 생성하고 처리한다.
- 아파치의 경우 하나의 쓰레드 당 하나의 커넥션이 1대1로 할당되지만, Nginx는 여러 커넥션들이 queue에 적재되고 이벤트 핸들러에서 비동기적으로 처리한다.

요청이 들어오면 OS의 이벤트 큐에 요청들이 쌓인다. 워커 프로세스는 각각 하나의 쓰레드로 구성되어 있고 계속 큐에서 이벤트를 꺼내서 처리한다.

> 이벤트 루프를 사용해서 하나의 쓰레드가 여러 커넥션을 처리할 수 있게 됬고, C10K 문제를 해결할 수 있었다.

### 단점
- Apache 웹 서버보다 지원하는 모듈이 다양하지 않다.



## CDN

CDN(Content Delivery Network)은 인터넷 사용자가 웹 사이트에 접속할 때, 해당 웹 사이트에 있는 컨텐츠(이미지, 비디오, 문서 등)들을 빠르게 제공하기 위한 분산 네트워크이다.

일반적으로, 웹 사이트에 접속할 때, 해당 웹 사이트가 호스팅되는 서버로부터 모든 컨텐츠를 받아와야 한다.하지만 CDN은 전 세계에 분산된 여러 대의 서버를 사용하여, 해당 컨텐츠를 더 빠르고 효율적으로 제공할 수 있도록 한다.

### CDN의 동작 방식

웹 사이트에서 CDN 사용 설정: 웹 사이트 소유자는 CDN을 사용하도록 설정하고, CDN 공급자로부터 CDN에 대한 엔드포인트 주소를 받는다.

컨텐츠 업로드 및 CDN 캐싱: CDN 공급자는 웹 사이트의 컨텐츠를 캐싱하기 위해 여러 대의 서버를 구축한다. 
웹 사이트 소유자는 CDN 엔드포인트 주소를 이용하여, 컨텐츠를 CDN 서버에 업로드한다.

CDN 요청 및 제공: 사용자가 웹 사이트에 접속하면, 웹 사이트의 HTML 페이지가 CDN 서버로부터 로드된다. 
이 때, HTML 페이지에 포함된 이미지, 비디오, 문서 등의 컨텐츠가 필요한 경우, CDN 서버에서 해당 컨텐츠를 빠르게 제공한다.

CDN을 통해 웹 사이트 소유자는 전 세계 어디서나 빠르게 가장 가까운 CDN 서버에서 컨텐츠를 제공할 수 있으며, 사용자는 웹 사이트에 더 빠르게 접속할 수 있다.
또한, CDN은 웹 사이트의 부하를 분산시켜 서버의 부하를 줄이고, 대역폭 비용을 절감할 수 있는 장점도 있다.

> 유튜브 같이 대형 콘텐츠 제공사들은 세계 곳곳에 있는 CDN 서버를 통해 빠르게 컨텐츠를 제공해준다. 만약 유튜브의 영상을 항상 메인 서버에서 받아와야 했다면 매우 느릴 것이다.

<br>

## LRU 캐싱

LRU (Least Recently Used) 캐싱은 캐시에서 가장 오래 전에 사용된 데이터를 삭제하는 알고리즘이다. 이 알고리즘은 캐시의 크기가 한정되어 있을 때, 캐시에 새로운 데이터가 삽입될 때마다 가장 오래전에 사용된 데이터를 삭제하여 캐시의 용량을 유지하면서 캐시의 효율성을 높일 수 있다.

만약, 캐시에 이미 있는 데이터가 참조되었다면, 해당 데이터의 위치를 가장 최근으로 업데이트한다. 이렇게 함으로써, 최근에 참조된 데이터를 빠르게 접근할 수 있도록 하며, 자주 사용되지 않은 데이터는 캐시에서 삭제된다.

LRU 캐싱은 **캐시의 크기가 한정되어 있을 때**, 캐시에서 가장 오래전에 사용된 데이터를 삭제함으로써 캐시의 공간을 효율적으로 관리할 수 있다. 그러나, 캐시의 크기가 계속해서 증가하거나, 데이터의 접근 패턴이 예측하기 어렵거나, 최근에 사용된 데이터와 오래된 데이터의 구분이 모호한 경우, LRU 캐싱의 효율성이 감소할 수 있다.

<br>

## daum.net을 쳤을 때 일어나는 과정을 네트워크 관점에서 설명해보아라

1. 주소창에 URL을 입력한다.
2. PC 내부의 Hosts file을 찾아본다.
3. PC 내부의 DNS 캐시를 찾아본다.
4. ISP에서 DNS를 조회하고 해당하는 IP를 반환해준다.
5. CDN 서비스가 사용자의 IP를 보고 위치를 판단한다. 그리고 사용자에게 가까운 서버 IP를 알려준다 (GSLB)
6. www.daum.net으로 TCP 커넥션을 맺는다.
7. TCP 연결이 성공하면 HTTP Request를 보낸다.
8. HTTP 응답이 response가 돌아온다.





