## 프로세스와 스레드

### 프로세스

- 프로그램이 메모리에 적재되어 CPU를 할당받아 실행 되는 것을 프로세스라고 한다.
- 프로세스는 개별적인 메모리 공간을 할당 받고, 해당 공간은 Code영역, Data영역, Heap영역 그리고 Stack 영역으로 이루어져 있다.

### 메모리의 각 영역의 특징
![스크린샷 2023-03-29 오후 10 02 26](https://user-images.githubusercontent.com/82302520/228544383-9bf12625-f190-4228-87fa-f954a96d5709.png)




**Code 영역**
- 실행한 프로그램의 코드가 적재되는 영역이다.

**Data 영역**
- 프로그램의 전역 변수와 static 변수가 저장되는 공간이다.

**Heap 영역**
- 개발자가 직접 할당/해제하는 공간으로 런타임의 객체가 생성/소멸 하는 공간이다.

**Stack 영역**
- 메서드의 매개변수, 지역번수가 저장되는 공간이다.

### 스레드

스레드는 한 프로세스 내에서 실행되는 기능의 단위이다. 각 스레드는 속해있는 프로세스의 Stack 메모리를 제외한 나머지 memory 영역을 공유할 수 있다.

## 멀티 스레드, 멀티 프로세스, 병렬 프로그래밍

### 멀티 스레드와 멀티 프로세스의 차이

- multi thread는 multi process보다 적은 메모리 공간을 차지하고 `Context Switching`이 빠르다.
    - 멀티 프로세스와 다르게 Context switching 시 캐시 메모리를 초기화할 필요가 없기 때문.
- multi process는 multi thread보다 많은 메모리공간과 CPU 시간을 차지한다.
- multi thread는 동기화 문제와 하나의 thread 장애로 전체 thread가 종료될 위험이 있다. (같은 메모리 공간을 공유하기 때문이다.)
- multi process는 하나의 process가 죽더라도 다른 process에 영향을 주지 않아 안정성이 높다.
- 프로세스 간 통신(IPC)는 자원이 많이 들어가지만 thread 간 통신은 프로세스에 할당된 heap 영역을 통해서 간편하게 할 수 있다.

> 멀티 쓰레드는 Context Switching이 빈번하게 일어나고, 데이터 공유가 빈번한 환경에서 유리하고, 멀티 프로세스는 작업의 안정성이 중요한 경우 유리하다.

**(추가)** 멀티 스레드와 멀티 프로세스의 차이로, 크롬과 인터넷 익스플로러의 멀티탭 구현 방식을 예로 들 수 있다.

- 인터넷 익스플로러는 멀티 쓰레드 방식을 사용
    - 자원을 효율적으로 사용한다는 장점이 있지만, 모든 멀티탭이 하나의 프로세스이기에 하나의 탭이 작동안하면 전체가 멈춘다.
- 크롬은 멀티 프로세스 방식을 사용
    - 하나의 탭마다 개별적인 프로세스가 동작하기에, 자원이 비효율적으로 사용되지만 독립적인 메모리 공간을 사용하기에 오류 발생 확률이 적다.

### 병렬 프로그래밍

병렬프로그래밍은 순차적인 직렬프로그램을 분할하고 분할된 단위를 동시에 병렬로 수행함으로써 성능을 향상시키는 프로그래밍 기술이며, 이러한 전반적인 과정을 병렬화라고 한다.

즉, 여러 프로그램을 동시에 실행하기 위해 작업 단위를 일정 시간으로 나누고(시분할) 특정 시간 동안 CPU를 각 프로그램의 쓰레드에게 할당해주는 방법을 말한다.


## 동기와 비동기

이건... 저번에 진행했던 스터디를 차근차근 복습하면 될것 같습니다 ㅎㅎ 너무 많이 했어

## 프로세스 동기화

운영체제는 프로세스 간의 자원 접근을 위한 매커니즘인 IPC를 제공하고, 기법으로는 파이프, 파일, 소켓, 공유메모리 등이 있다.

<img width="400" alt="ipc" src="https://user-images.githubusercontent.com/82302520/228541481-923ed523-8379-4e3c-b75d-28335694eb76.png">

### 공유 메모리 방식


통신을 원하는 프로세스들이 특정한 메모리 공간을 할당 받고, 그 공간을 통해 데이터를 주고 받는 방식을 말한다.

**공유 메모리 방식의 순서**
1. 송신 측 프로세스가 커널에게 공유 메모리 영역 할당을 요청한다.
2. 커널은 특정한 영역을 공유 메모리 영역으로 할당하고 더이상 그 영역에 관여하지 않는다.
3. 송신 측과 수신 측 프로세스는 일반 메모리 접근처럼 자유롭게 해당 영역을 통해 데이터를 주고받는다.

**공유 메모리 방식의 장점**
- 따로 커널의 관리를 받지 않기 때문에 데이터 전송을 빠르게 진행할 수 있다.

**공유 메모리 방식의 단점**
- 커널의 관리를 따로 받지 않고, 같은 영역을 여러 프로세스가 공유하기 때문에 동시성 이슈를 해결하기 위한 별도의 메커니즘을 구축해야 한다.

### 메세지 전달 방식

데이터의 실제 전송을 커널에서 관리해주는 방식이다. 파이프, 소켓 등이 이 방식에 속한다.

**메세지 전달 방식의 순서**
1. 송신 측 프로세스가 커널에게 send(message) 시스템 콜을 호출해서 메세지 전달을 요청한다.
2. 커널은 해당 메세지를 받아서 receive(message) 시스템 콜을 통해 수신 측에 메세지를 전달한다.

**메세지 전달 방식의 장점**
- 항상 커널의 제어를 받기 때문에 공유 메모리 방식에 비해 통신 속도가 느리다.

**메세지 전달 방식의 단점**
- 커널의 관리를 받기 때문에 안전한 통신을 진행할 수 있고, 동시성 이슈도 커널이 알아서 해결해준다.

## 스케쥴러

프로세스가 생성되어 실행될 떄 필요한 시스템의 여러자원을 해당 프로세스에게 할당하는 작업을 뜻 하며, 대기 시간은 최소화 하고 최대한 공평하게 처리하는 것을 목적으로한다.

### 기간에 따른 스케쥴러 구분

**장기 (Long-term scheduling)**
- 어떤 프로세스가 시스템의 자원을 차지할 수 있도록 할 것인가를 결정하여 아래 준비(ready) 상태 큐로 보내는 작업을 의미한다.
- 상위 스케줄링이라고도 하며, 작업 스케줄러에 의해 수행된다.
- 수행 빈도 적고, 느리다.

**중기 (middle-term scheduling)**
- 어떤 프로세스들이 CPU를 할당 받을 것인지 결정하는 작업을 의미한다.
- CPU를 할당받으려는 프로세스가 많을 경우 프로세스를 일시 대기(waiting)시킨 후 활성화해서 일시적으로 부하를 조절한다.
- 스왑 인/아웃 결정 (메모리 부족 시 swap out, 남으면 swap in) 한다.

**단기 (Short-term scheduling)**
- 프로세스가 실행되기 위해 CPU를 할당받는 시기와 특정 프로세스를 지정하는 작업을 의미한다.
- 프로세서 스케줄링, 하위 스케줄링이라고도 한다.
- 프로세서 스케줄링 및 문맥 교환은 프로세서 스케줄러에 의해 수행한다.
- 자주 수행되고 빠르다.

### 프로세스 상태 전이

<img width="400" alt="스크린샷 2023-03-29 오후 7 27 11" src="https://user-images.githubusercontent.com/82302520/228540867-05b88c0b-a173-4221-80fe-0b73de105502.png">

생성(New)
- 제일 첫번째로 New에서 Ready로 전이되는 과정이다. 프로세스가 생성되고 나서 생성된 프로세스는 준비(Ready) 상태에 머문다. 준비 상태는 CPU를 점유하고 있는 상태가 아니라, CPU를 점유하길 희망하는 상태이다. 준비 상태에서 실행 상태로 넘어가려면 작업 스케줄러가 선택해 주어야만 한다.

디스패치(Dispatch)
- 디스패치란 준비 상태에서 실행 상태로 전이되는 과정을 말하며, 이는 작업 스케줄러가 해당 프로세스를 선택하여 실행되어지는 것으로, 이때 실행된 프로세스가 CPU를 점유하게 된다.

인터럽트(Interrupt)
- 인터럽트 신호를 받게되면, 실행중이던 프로세스는 준비 상태로 전이되고, 우선순위(Priority)가 높은 프로세스를 실행 상태로 전이시킨다. (프로세스는 각각 우선순위를 부여받고, 우선순위에 따라 프로세스가 준비 상태로 전이되거나, 실행 상태로 전이된다.)

입출력 혹은 이벤트 대기(I/O or event wait)
- CPU를 점유하고 있는 프로세스가 입출력 처리를 해야만 하는 상황이라면, 실행되고 있는 프로세스는 실행 상태에서 대기/보류 상태로 바뀐다. 그리고 대기 상태로 바뀐 프로세스는 입출력 처리가 모두 끝날때까지 대기 상태로 머문다. 그리고 실행 상태이던 프로세스가 대기 상태로 전이됨과 함께, 준비 상태이던 또다른 프로세스가 실행 상태로 전이된다. 또한 대기 상태인 프로세스는 우선순위가 부여되지 않으며 스케줄러에 의해 선택될 수 없다.

입출력 혹은 이벤트 완료(I/O or event completion)
- 입출력 처리가 끝난 프로세스는 대기 상태에서 준비 상태로 전이되어 스케줄러에게 선택될 수 있게 된다.


### 비선점 vs 선점 스케줄링

비선점 스케줄링
- 프로세스가 입출력 요구 등으로 CPU를 자진 반납할 때까지 CPU에 의한 실행을 보장해주는 스케줄링이다. 작업 실행 시간 전체 또는 한번의 CPU 배당에 적용된다.
- 모든 프로세스에 대한 요구를 공정하게 처리할 수 있지만, 짧은 작업을 수행하는 프로세스가 긴 작업 종료 시까지 대기해야할 수도 있다. 
- 처리시간 편차가 적은 특정 프로세스 환경에 용이

선점 스케줄링

- 시분할 시스템에서 타임슬라이스가 소진되었거나 인터럽트 혹은 시스템 호출 종료로 인한 여파로 높은 우선순위의 프로세스가 현 프로세스보다를 강제로 중단시키고 CPU를 회수하는 스케쥴링 방식이다.
- 비교적 응답이 빠르다는 장점이 있지만, 처리 시간을 예측하기 힘들고 높은 우선순위 프로세스들이 계속 들어오는 경우 오버헤드를 초래
- 실시간 응답환경, Deadline 응답환경 등 우선순위가 높은 프로세스를 빠르게 처리해야 할 경우 등에 유용


### CPU 스케쥴링 종류
- 비선점 스케쥴링 : FCFS(First-Come-Fist-Served) / 최단 작업 우선(SJF, Shortest Job First) / 우선순위 스케줄링 (Priority Scheduling)
- 선점 스케쥴링	: 라운드 로빈 스케줄링 / 다단계 큐 스케줄링 / 다단계 피드백 큐 스케줄링


## 교착 상태의 개념과 조건

둘 이상의 스레드가 각기 다른 스레드가 점유하고 있는 자원을 서로 기다릴 때, 무한 대기에 빠지는 상황을 말한다.

### 데드락 발생 조건

deadlock이 발생하는 조건은 상호 배제, 점유 대기, 비선점, 순환 대기이다. 이 4가지 조건이 동시에 성립할 때 교착 상태가 발생한다.

1. **상호 배제**
    - 동시에 한 thread만 자원을 점유할 수 있는 상황
    - 다른 thread가 자원을 사용하려면 자원이 방출될 때까지 기다려야 한다.
2. **점유 대기**
    - thread가 자원을 보유한 상태에서 다른 thread가 보유한 자원을 추가로 기다리는 상황
3. **비선점**
    - 다른 thread가 사용 중인 자원을 강제로 선점할 수 없는 상황
    - 자원을 점유하고 있는 thread에 의해서만 자원이 방출됨
4. **순환 대기**
    - 대기 중인 thread들이 순환 형태로 자원을 대기하고 있는 상황이다.

### 데드락 해결 방법

| 기법 | 설명 | 비고                                                                                                   |
| --- | --- |------------------------------------------------------------------------------------------------------|
| 무시 | deadlock 발생 확률이 낮은 시스템에서 아무런 조치도 취하지 않고 deadlock을 무시하는 방법 | - 무시 기법은 시스템 성능 저하가 없다는 큰 장점이 있다. <br/>- 현대 시스템에서는 deadlock이 잘 발생하지 않고, 해결 비용이 크기 때문에 무시 방법이 많이 사용된다. |
| 예방 | 교착 상태의 4가지 발생 조건중 하나가 성립하지 않게 하는 방법 | - 순환 대기 조건이 성립하지 않도록 하는 것이 현실적으로 가능한 예방 기법이다. <br/>- 자원 사용의 효율성이 떨어지고 비용이 큽니다.                       |
| 회피 | thread가 앞으로 자원을 어떻게 요청할지에 대한 정보를 통해 순환 대기 상태가 발생하지 않도록 자원을 할당하는 방법 | - 자원 할당 그래프 알고리즘, 은행원 알고리즘 등을 사용하여 자원을 할당하여 deadlock을 회피한다.                                          |
| 탐지회복 | 시스템 검사를 통해 deadlock 발생을 탐지하고, 이를 회복시키는 방법 | - 자원 사용의 효율성이 떨어지고 비용이 크다.                                                                           |

### 뮤텍스 vs 세마포어

**뮤텍스**

뮤텍스는 자원에 대한 접근을 동기화하기 위해 사용되는 상호배제 기술이다. 뮤텍스는 Locking 메커니즘으로 오직 하나의 쓰레드만이 동일한 시점에 뮤텍스를 얻어 임계 영역(Critical Section)에 들어올 수 있다. 그리고 오직 **이 쓰레드만이 임계 영역에서 나갈 때 뮤텍스를 해제할 수 있다**.

**세마포어**

- 세마포어는 Signaling 메커니즘이라는 점에서 뮤텍스와 다르다. 세마포어는 락을 걸지 않은 쓰레드도 Signal을 보내 락을 해제할 수 있다는 점에서, wait 함수를 호출한 쓰레드만이 signal 함수를 호출할 수 있는 뮤텍스와 다르다.
- 세마포어는 동기화를 위해 wait와 signal이라는 2개의 atomic operations를 사용한다. wait를 호출하면 세마포어의 카운트를 1줄이고, 세마포어의 카운트가 0보다 작거나 같아질 경우에 락이 실행된다.
- 세마포어의 카운트가 0보다 작거나 같아져 동기화가 실행된 상황에, 다른 쓰레드가 signal 함수를 호출하면 세마포어의 카운트가 1증가하고, 해당 쓰레드는 락에서 나올 수 있다.

**세마포어의 종류**
- Counting Semaphores : 카운팅 세마포어는 세마포어의 카운트가 양의 정수값을 가지며, 설정한 값만큼 쓰레드를 허용하고 그 이상의 쓰레드가 자원에 접근하면 락이 실행된다.
- Binary Semaphore : 바이너리 세마포어는 세마포어의 카운트가 1이며 Mutex처럼 사용될 수 있다.

> 뮤텍스는 Locking 메커니즘으로 락을 걸은 쓰레드만이 임계 영역을 나갈때 락을 해제할 수 있다. 하지만 세마포어는 Signaling 메커니즘으로 락을 걸지 않은 쓰레드도 signal을 사용해 락을 해제할 수 있다. 세마포어의 카운트를 1로 설정하면 뮤텍스처럼 활용할 수 있다.

### 이진 세마포어 vs 뮤텍스

- 공통점 : 한번에 하나의 쓰레드만 공유 자원에 접근할 수 있다.
- 차이점 : 뮤텍스는 락을 건 쓰레드만 다시 락을 해제할 수 있지만, 이진 세마포어는 대기하고 있는 다른 쓰레드도 Signal을 보내서 해당 락을 해제할 수 있다.

> 즉, 뮤텍스는 자원을 사용하고 있는 쓰레드에 문제가 생겨서 락이 걸린채로 죽으면 그대로 데드락으로 가고, 이진 세마포어는 다른 쓰레드가 락을 대신 해제해줄 수 있기에 데드락의 가능성이 적다.

## 메모리 관리 전략

### Page

![스크린샷 2023-03-29 오후 9 55 14](https://user-images.githubusercontent.com/82302520/228542478-ba81822f-b180-4e4e-834c-dcb9a3386fb2.png)

Paging이란 process가 할당받은 메모리 공간을 일정한 page 단위로 나누어, 물리 메모리에서 연속되지 않는 서로 다른 위치에 저장하는 메모리 관리 기법이다.

### segmentation
![스크린샷 2023-03-29 오후 9 56 43](https://user-images.githubusercontent.com/82302520/228542502-e096b6e8-18c1-4151-b837-7f9d6c3a5059.png)

- segmentation 기법은 process가 할당받은 메모리 공간을 **논리적 의미 단위(segment)**로 나누어, 연속되지 않는 물리 메모리 공간에 할당될 수 있도록 하는 메모리 관리 기법이다.
- 일반적으로 process의 메모리 영역 중 Code, Data, Heap, Stack 등의 기능 단위로 segment를 정의하는 경우가 많다.


## 가상 메모리

가상메모리는 실제의 물리 메모리 개념과 개발자 입장의 논리 메모리 개념을 분리한 것이다.
이렇게 함으로써 개발자가 메모리 크기에 관련한 문제를 염려할 필요 없이 쉽게 프로그램을 작성할 수 있게 해준다.

운영체제는 가상 메모리 기법을 통해 프로그램의 논리적주소 영역에서 필요한 부분만 물리적 메모리에 적재하고, 직접적으로 필요하지 않은 메모리 공간은 디스크에 스왑한다.

> 가상 메모리가 나오기 전에는 프로세스가 직접 메모리에 접근할 수 있었기에, 특정 프로세스 하나가 장애가 나면 전체 메모리에 영향을 줄 수도 있었다고 한다. 가상 메모리의 핵심은 메모리의 제어권을 완전히 운영체제가 가지고 왔다는 부분에 있다.

### 논리적 주소 vs 물리적 주소

**물리적 주소**

- 실제 메모리의 주소를 말한다.

**논리적 주소**
- 가상 메모리 상에서 프로세스가 할당 받는 주소를 말한다. 모든 프로세스가 0번지 부터 시작하는 주소값을 할당받는다.

> 프로세스는 실제 메모리의 주소가 신경 쓸 필요 없이 그냥 운영체제가 준 대로 0번지 부터 사용하면 된다.
### 요구 페이징

당장 사용될 주소 공간을 **page 단위**로 메모리에 적재하는 방법을 **요구 페이징(demand paging)** 이라고 한다. 요구 페이징 기법에서는 특정 page에 대해 cpu의 요청이 들어온 후에 해당 page를 메모리에 적재한다. 당장 실행에 필요한 page만을 메모리에 적재하기 때문에 메모리 사용량이 감소하고, 프로세스 전체를 메모리에 적재하는 입출력 오버헤드도 감소하는 장점이 있다.

요구 페이징 기법에서는 **유효/무효 비트(valid/invalid bit)** 를 두어 각 page가 메모리에 존재하는지 표시하게 됩니다.

### Page fault

CPU가 **무효 비트(invalid bit)로 표시된 page에 엑세스**하는 상황을 **page fault**라고 한다.

CPU가 무효 page에 접근하면 주소 변환을 담당하는 하드웨어인 MMU가 **page fault trap을 발생**시킨다. Page fault가 발생하면 디스크로부터 해당 페이지를 가지고 온다.

## 캐시의 지역성

캐시가 효율적으로 동작하려면, 캐시의 적중률을 극대화 시켜야 한다. 캐시에 저장할 데이터가 지역성(Locality)을 가져야 한다.
지역성이란, 데이터 접근이 시간적, 혹은 공간적으로 가깝게 일어나는 것을 의미한다.
지역성의 전제 조건으로 프로그램은 모든 코드나 데이터를 균등하게 접근하지 않는다는 특성을 기본으로 한다.즉, 지역성(Locality)이란 기억장치 내의 정보를 균일하게 접근하는 것이 아닌 어느 한 순간에 특정 부분을 집중적으로 참조하는 특성이다.


### 지역성(Locality)의 종류
**시간적 지역성**

- 특정 데이터가 한번 접근되었을 경우, 가까운 미래에 또 한번 데이터에 접근할 가능성이 높은 것
- 메모리 상의 같은 주소에 여러 차례 읽기 쓰기를 수행할 경우, 상대적으로 작은 크기의 캐시를 사용해도 효율성을 꾀할 수 있다.

**공간적 지역성**

- 특정 데이터와 가까운 주소가 순서대로 접근되었을 경우.
- CPU 캐시나 디스크 캐시의 경우 한 메모리 주소에 접근할 때 그 주소뿐 아니라 해당 블록을 전부 캐시에 가져오게 된다.
    - 이때 메모리 주소를 오름차순이나 내림차순으로 접근한다면, 캐시에 이미 저장된 같은 블록의 데이터를 접근하게 되므로 캐시의 효율성이 크게 향상된다.

## 외부 단편화와 내부 단편화

물리적 메모리 공간이 작은 조각으로 나눠져서 메모리가 충분히 존재함에도 할당이 불가능한 상태를 보고 메모리 단편화가 발생했다고 말한다.

**외부 단편화 문제**
- 메모리상의 비어있는 공간의 크기가 작아서, 빈 메모리 공간임에도 활용되지 못하는 문제다.

**내부 단편화 문제**
- 프로세스가 필요한 양보다 더 큰 메모리가 할당되어서 메모리 공간이 낭비되는 상황이다.

### Page 기법에서의 단편화
process의 논리적 주소 공간과 물리적 메모리가 같은 크기의 page 단위로 나누어지기 때문에 외부 단편화 문제가 발생하지 않습니다. 하지만 process 주소 공간의 크기가 page 크기의 배수라는 보장이 없기 때문에, 프로세스의 주소 공간 중 가장 마지막에 위치한 page에서는 내부 단편화 문제가 발생할 가능성이 있다.

### Segmentation 기법에서의 단편화

segment는 segment 크기에 딱 맞게 메모리가 할당되기 때문에 내부 단편화가 발생하지 않는다. 하지만 서로 다른 크기의 segment들이 메모리에 적재되고 제거되는 일이 반복되면, 외부 단편화 문제가 발생할 수 있다.

### paged segmentation

paged segmentation이란 segmentation을 기본으로 하되 이를 다시 동일 크기의 page로 나누어 물리 메모리에 할당하는 메모리 관리 기법이다. 즉, 프로그램을 **의미 단위의 segment**로 나누고 개별 **segment의 크기를 page의 배수**가 되도록 하는 방법이다.

